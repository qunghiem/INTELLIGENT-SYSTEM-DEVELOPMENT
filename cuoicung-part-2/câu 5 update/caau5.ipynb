{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shopee Data Sample:\n",
      "                                     ID Product ID Customer ID  Rating  \\\n",
      "0  422aa214-ec7b-47fd-9ba9-34a9bc98084d     P95531        C183       3   \n",
      "1  d91577d2-9315-42f7-a063-1a58624bdf1e     P91287        C175       5   \n",
      "2  fa15702a-d7db-4feb-b769-84255cc8582d     P99714        C190       4   \n",
      "3  bcc56f54-c83d-4b18-a24c-41f00c68df58     P99019        C190       2   \n",
      "4  81b8eb26-d1fb-4d00-b53b-363c3e55df7a     P91560        C132       5   \n",
      "\n",
      "                                             Comment        Date    Category  \\\n",
      "0  Fight increase sport benefit college create si...  2024-05-27     Quần áo   \n",
      "1  Indicate up we meet back loss she result hair ...  2024-03-15    Phụ kiện   \n",
      "2  Baby light unit spend weight act again will se...  2024-04-12  Đồ điện tử   \n",
      "3                  Laugh draw do school few feeling.  2024-11-16     Máy ảnh   \n",
      "4  By outside name city none task increase never ...  2024-01-21     Quần áo   \n",
      "\n",
      "  Sentiment  Likes  Dislikes          Location  \\\n",
      "0  Negative     51         7     Torresborough   \n",
      "1   Neutral     22         1       Stanleystad   \n",
      "2  Negative     78         4  East Phillipside   \n",
      "3  Positive     23         2          Longport   \n",
      "4  Positive     41         2        Jameshaven   \n",
      "\n",
      "                        Product Features  \n",
      "0        Product how here state me next.  \n",
      "1  Staff order carry western issue just.  \n",
      "2             Let put feel only section.  \n",
      "3                      Almost goal book.  \n",
      "4    Around involve low ball affect one.  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "# Khởi tạo Faker để tạo dữ liệu giả\n",
    "fake = Faker()\n",
    "\n",
    "# Hàm sinh dữ liệu cho Shopee\n",
    "def generate_shopee_data(num_records=10):\n",
    "    data = []\n",
    "    categories = ['Quần áo', 'Đồ điện tử', 'Máy ảnh', 'Phụ kiện', 'Giày thể thao']\n",
    "    sentiments = ['Positive', 'Neutral', 'Negative']\n",
    "    \n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            'ID': fake.uuid4(),\n",
    "            'Product ID': f\"P{random.randint(90000, 99999)}\",\n",
    "            'Customer ID': f\"C{random.randint(101, 200)}\",\n",
    "            'Rating': random.randint(1, 5),\n",
    "            'Comment': fake.sentence(nb_words=10),\n",
    "            'Date': fake.date_this_year(),\n",
    "            'Category': random.choice(categories),\n",
    "            'Sentiment': random.choice(sentiments),\n",
    "            'Likes': random.randint(0, 100),\n",
    "            'Dislikes': random.randint(0, 10),\n",
    "            'Location': fake.city(),\n",
    "            'Product Features': fake.sentence(nb_words=5)\n",
    "        }\n",
    "        data.append(record)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Tạo dữ liệu cho Shopee\n",
    "shopee_data = generate_shopee_data(10)\n",
    "\n",
    "# Lưu dữ liệu vào file CSV (tùy chọn)\n",
    "shopee_data.to_csv('shopee_comments.csv', index=False)\n",
    "\n",
    "# Hiển thị một vài dòng dữ liệu\n",
    "print(\"Shopee Data Sample:\")\n",
    "print(shopee_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     ID Product ID Customer ID  Rating  \\\n",
      "0  422aa214-ec7b-47fd-9ba9-34a9bc98084d     P95531        C183       3   \n",
      "1  d91577d2-9315-42f7-a063-1a58624bdf1e     P91287        C175       5   \n",
      "2  fa15702a-d7db-4feb-b769-84255cc8582d     P99714        C190       4   \n",
      "3  bcc56f54-c83d-4b18-a24c-41f00c68df58     P99019        C190       2   \n",
      "4  81b8eb26-d1fb-4d00-b53b-363c3e55df7a     P91560        C132       5   \n",
      "\n",
      "                                             Comment       Date    Category  \\\n",
      "0  fight increase sport benefit college create si... 2024-05-27     Quần áo   \n",
      "1  indicate up we meet back loss she result hair ... 2024-03-15    Phụ kiện   \n",
      "2  baby light unit spend weight act again will se... 2024-04-12  Đồ điện tử   \n",
      "3                  laugh draw do school few feeling  2024-11-16     Máy ảnh   \n",
      "4  by outside name city none task increase never ... 2024-01-21     Quần áo   \n",
      "\n",
      "  Sentiment  Likes  Dislikes          Location  \\\n",
      "0  Negative     51         7     Torresborough   \n",
      "1   Neutral     22         1       Stanleystad   \n",
      "2  Negative     78         4  East Phillipside   \n",
      "3  Positive     23         2          Longport   \n",
      "4  Positive     41         2        Jameshaven   \n",
      "\n",
      "                        Product Features  \n",
      "0        Product how here state me next.  \n",
      "1  Staff order carry western issue just.  \n",
      "2             Let put feel only section.  \n",
      "3                      Almost goal book.  \n",
      "4    Around involve low ball affect one.  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Giả sử bạn đã có DataFrame shopee_data sau khi sinh ra dữ liệu\n",
    "# Chúng ta sẽ làm tiền xử lý cho dữ liệu này\n",
    "\n",
    "# 1. Xử lý dữ liệu thiếu\n",
    "shopee_data = shopee_data.dropna()  # Loại bỏ các dòng có dữ liệu thiếu\n",
    "\n",
    "# 2. Chuyển đổi cột 'Date' về định dạng datetime\n",
    "shopee_data['Date'] = pd.to_datetime(shopee_data['Date'], errors='coerce')\n",
    "\n",
    "# 3. Chuyển cột 'Rating' thành kiểu dữ liệu int (nếu chưa phải)\n",
    "shopee_data['Rating'] = shopee_data['Rating'].astype(int)\n",
    "\n",
    "# 4. Loại bỏ các bình luận ngắn (dưới 5 từ chẳng hạn)\n",
    "shopee_data = shopee_data[shopee_data['Comment'].apply(lambda x: len(x.split()) >= 5)]\n",
    "\n",
    "# 5. Chuẩn hóa các văn bản trong cột 'Comment' (chuyển thành chữ thường, loại bỏ ký tự đặc biệt)\n",
    "shopee_data['Comment'] = shopee_data['Comment'].str.lower()  # Chuyển thành chữ thường\n",
    "shopee_data['Comment'] = shopee_data['Comment'].str.replace(r'\\W', ' ', regex=True)  # Loại bỏ ký tự đặc biệt\n",
    "\n",
    "# 6. Kiểm tra các cột 'Likes' và 'Dislikes' để chắc chắn không có giá trị âm\n",
    "shopee_data['Likes'] = shopee_data['Likes'].apply(lambda x: max(x, 0))\n",
    "shopee_data['Dislikes'] = shopee_data['Dislikes'].apply(lambda x: max(x, 0))\n",
    "\n",
    "# 7. Đảm bảo cột 'Sentiment' là một trong các giá trị hợp lệ\n",
    "sentiment_values = ['Positive', 'Neutral', 'Negative']\n",
    "shopee_data = shopee_data[shopee_data['Sentiment'].isin(sentiment_values)]\n",
    "\n",
    "# 8. Xử lý cột 'Location' để đảm bảo không có giá trị thiếu\n",
    "shopee_data['Location'] = shopee_data['Location'].fillna('Unknown')\n",
    "\n",
    "# 9. Đảm bảo các cột số như 'Likes', 'Dislikes' không có giá trị ngoại lệ\n",
    "shopee_data['Likes'] = shopee_data['Likes'].clip(lower=0, upper=100)  # Giới hạn Likes trong phạm vi hợp lý\n",
    "shopee_data['Dislikes'] = shopee_data['Dislikes'].clip(lower=0, upper=10)  # Giới hạn Dislikes trong phạm vi hợp lý\n",
    "\n",
    "# 10. Tạo thêm các cột mới nếu cần, ví dụ: phân tích Sentiment (Nếu bạn muốn phân tích)\n",
    "# Cột Sentiment đã có sẵn, nếu bạn muốn thực hiện phân tích cảm xúc nâng cao hơn, có thể dùng thư viện như `TextBlob`\n",
    "\n",
    "# Kiểm tra dữ liệu sau khi tiền xử lý\n",
    "print(shopee_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.6667 - loss: 0.6960\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6667 - loss: 0.6555\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6667 - loss: 0.6231\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6667 - loss: 0.5966\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6667 - loss: 0.5731\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.0000e+00 - loss: 0.8988\n",
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Giả sử bạn đã có dữ liệu\n",
    "texts = [\"Tuyệt vời, rất thích!\", \"Chất lượng không tốt\", \"Sản phẩm ổn\", \"Dịch vụ tệ\"]\n",
    "labels = [1, 0, 1, 0]  # 1 = Positive, 0 = Negative\n",
    "\n",
    "# Tiền xử lý văn bản\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "X = pad_sequences(sequences, maxlen=100)\n",
    "\n",
    "# Chia dữ liệu thành train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2)\n",
    "\n",
    "# Đảm bảo dữ liệu X_train và X_test là numpy array\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Xây dựng mô hình CNN\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=128, input_length=100))\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))  # Sử dụng sigmoid cho phân loại nhị phân\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy[1]*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - accuracy: 0.3333 - loss: 0.6982\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.6667 - loss: 0.6809\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.6667 - loss: 0.6681\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.6667 - loss: 0.6605\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.6667 - loss: 0.6416\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896ms/step - accuracy: 0.0000e+00 - loss: 0.8198\n",
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "# Xây dựng mô hình LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=128, input_length=100))\n",
    "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Phân loại nhị phân\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy[1]*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, TFBertForSequenceClassification\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tải tokenizer và mô hình BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Chuẩn bị dữ liệu\n",
    "texts = [\"Tuyệt vời, rất thích!\", \"Chất lượng không tốt\", \"Sản phẩm ổn\", \"Dịch vụ tệ\"]\n",
    "labels = [1, 0, 1, 0]  # 1 = Positive, 0 = Negative\n",
    "\n",
    "# Tokenize văn bản\n",
    "encodings = tokenizer(texts, truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Chia dữ liệu thành train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(encodings['input_ids'], labels, test_size=0.2)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model.compile(optimizer=Adam(learning_rate=2e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(np.array(X_train), np.array(y_train), epochs=3, batch_size=8)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "accuracy = model.evaluate(np.array(X_test), np.array(y_test))\n",
    "print(f'Accuracy: {accuracy[1]*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

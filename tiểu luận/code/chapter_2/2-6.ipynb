{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.4551\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3006\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2099\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1295\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0513\n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0113\n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039\n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020\n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013    \n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0010    \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step\n",
      "Dự đoán giá cổ phiếu ngày mai: -0.36\n"
     ]
    }
   ],
   "source": [
    "# Dự đoán giá cổ phiếu ngày mai dựa trên giá của 10 ngày trước.\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Dữ liệu giả lập: Chuỗi giá cổ phiếu\n",
    "data = np.sin(np.linspace(0, 100, 500))  # Sóng sin giả lập\n",
    "X = np.array([data[i:i+10] for i in range(len(data)-10)])\n",
    "y = data[10:]\n",
    "\n",
    "# Reshape dữ liệu cho LSTM\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Xây dựng mô hình LSTM\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(10, 1)),\n",
    "    Dense(1)  # Dự đoán giá trị tiếp theo\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model.fit(X, y, epochs=10, batch_size=32)\n",
    "\n",
    "# Dự đoán giá tiếp theo\n",
    "test_input = data[-10:].reshape(1, 10, 1)\n",
    "predicted_price = model.predict(test_input)\n",
    "print(f\"Dự đoán giá cổ phiếu ngày mai: {predicted_price[0][0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.6667 - loss: 0.6174\n",
      "Epoch 2/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3333 - loss: 0.7537    \n",
      "Epoch 3/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5000 - loss: 0.6875 \n",
      "Epoch 4/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 0.6400 \n",
      "Epoch 5/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3333 - loss: 0.7284     \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
      "Câu: 'I hate this' -> Tiêu cực (0.49)\n",
      "Câu: 'This is fantastic' -> Tiêu cực (0.46)\n"
     ]
    }
   ],
   "source": [
    "# Phân loại các câu là tích cực hoặc tiêu cực.\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "# Dữ liệu giả lập\n",
    "texts = [\"I love this product\", \"This is terrible\", \"Amazing experience\", \"Not good at all\"]\n",
    "labels = np.array([1, 0, 1, 0])  # 1: Tích cực, 0: Tiêu cực\n",
    "\n",
    "# Tokenizer và Padding\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "X = tokenizer.texts_to_sequences(texts)\n",
    "X = pad_sequences(X, maxlen=10)  # Đảm bảo tất cả chuỗi có cùng độ dài\n",
    "\n",
    "# Reshape dữ liệu để phù hợp với LSTM\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # Thêm một trục để LSTM nhận diện\n",
    "\n",
    "# Xây dựng mô hình LSTM\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(X.shape[1], X.shape[2])),\n",
    "    Dense(1, activation='sigmoid')  # Phân loại nhị phân\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model.fit(X, labels, epochs=5, batch_size=2)\n",
    "\n",
    "# Dự đoán cảm xúc\n",
    "new_texts = [\"I hate this\", \"This is fantastic\"]\n",
    "new_X = tokenizer.texts_to_sequences(new_texts)\n",
    "new_X = pad_sequences(new_X, maxlen=10)\n",
    "new_X = new_X.reshape((new_X.shape[0], new_X.shape[1], 1))  # Reshape để phù hợp với mô hình\n",
    "\n",
    "predictions = model.predict(new_X)\n",
    "\n",
    "for i, text in enumerate(new_texts):\n",
    "    sentiment = \"Tích cực\" if predictions[i][0] >= 0.5 else \"Tiêu cực\"\n",
    "    print(f\"Câu: '{text}' -> {sentiment} ({predictions[i][0]:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.5090 - loss: 1.1993\n",
      "Epoch 2/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9833 - loss: 0.0853\n",
      "Epoch 3/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0062\n",
      "Epoch 4/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0027\n",
      "Epoch 5/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 6/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 7/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.7710e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1128e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.0119e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.9047e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.2066e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.6076e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.2578e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.8295e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 2.5056e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.2517e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.9629e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.8092e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.6759e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.5521e-04\n",
      "WARNING:tensorflow:5 out of the last 20 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001BEDF601120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Chuỗi tín hiệu cảm biến: [ 4  8 22 42 43]\n",
      "Thông báo dự đoán: [1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "import numpy as np\n",
    "\n",
    "# Tạo dữ liệu giả lập với quy luật\n",
    "num_samples = 1000  # Số lượng mẫu dữ liệu\n",
    "max_sequence_length = 5  # Độ dài tối đa của chuỗi\n",
    "input_vocab_size = 50  # Số lượng từ hoặc tín hiệu trong đầu vào\n",
    "output_vocab_size = 5  # Số lượng thông báo đầu ra (5 loại thông báo)\n",
    "\n",
    "# Quy luật: Nếu giá trị tín hiệu tăng dần, thông báo là \"tăng nhiệt độ\"\n",
    "encoder_input_data = []\n",
    "decoder_input_data = []\n",
    "decoder_output_data = []\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    signal = np.sort(np.random.randint(1, input_vocab_size, max_sequence_length))  # Tín hiệu tăng dần\n",
    "    encoder_input_data.append(signal)\n",
    "\n",
    "    if np.all(np.diff(signal) > 0):  # Nếu tín hiệu tăng dần\n",
    "        message = [1, 1, 1, 0, 0]  # Mã hóa thông báo \"tăng nhiệt độ\"\n",
    "    else:\n",
    "        message = [2, 2, 2, 0, 0]  # Mã hóa thông báo khác\n",
    "\n",
    "    decoder_input_data.append(message[:-1])\n",
    "    decoder_output_data.append(message[1:])\n",
    "\n",
    "# Chuyển dữ liệu thành numpy array\n",
    "encoder_input_data = np.array(encoder_input_data)\n",
    "decoder_input_data = np.array(decoder_input_data)\n",
    "decoder_output_data = np.array(decoder_output_data)\n",
    "\n",
    "# One-hot encode đầu ra\n",
    "decoder_output_data_one_hot = np.zeros((num_samples, max_sequence_length - 1, output_vocab_size), dtype=\"float32\")\n",
    "for i in range(num_samples):\n",
    "    for t, word in enumerate(decoder_output_data[i]):\n",
    "        decoder_output_data_one_hot[i, t, word] = 1\n",
    "\n",
    "# Xây dựng mô hình Seq2Seq\n",
    "# 1. Encoder\n",
    "encoder_inputs = Input(shape=(max_sequence_length,))\n",
    "encoder_embedding = Embedding(input_dim=input_vocab_size, output_dim=128)(encoder_inputs)\n",
    "encoder_lstm = LSTM(128, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# 2. Decoder\n",
    "decoder_inputs = Input(shape=(max_sequence_length - 1,))\n",
    "decoder_embedding = Embedding(input_dim=output_vocab_size, output_dim=128)(decoder_inputs)\n",
    "decoder_lstm = LSTM(128, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(output_vocab_size, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Kết hợp Encoder và Decoder\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_output_data_one_hot, batch_size=32, epochs=20)\n",
    "\n",
    "# Mô hình dự đoán (Inference)\n",
    "# Encoder Model\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder Model\n",
    "decoder_state_input_h = Input(shape=(128,))\n",
    "decoder_state_input_c = Input(shape=(128,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_lstm_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_embedding, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_lstm_outputs)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# Hàm dịch chuỗi tín hiệu IoT\n",
    "def decode_sequence(input_seq):\n",
    "    # Mã hóa chuỗi đầu vào thành trạng thái\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Khởi tạo chuỗi đầu vào cho Decoder\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = 1  # Bắt đầu với token \"start\"\n",
    "\n",
    "    # Dịch chuỗi tín hiệu\n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Lấy từ có xác suất cao nhất\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        decoded_sentence.append(sampled_token_index)\n",
    "\n",
    "        # Kiểm tra điều kiện dừng\n",
    "        if sampled_token_index == 0 or len(decoded_sentence) > max_sequence_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Cập nhật chuỗi đầu vào\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Cập nhật trạng thái\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "# Dịch chuỗi tín hiệu mới\n",
    "test_input_seq = encoder_input_data[0:1]\n",
    "decoded_sentence = decode_sequence(test_input_seq)\n",
    "\n",
    "# Hiển thị kết quả\n",
    "print(\"Chuỗi tín hiệu cảm biến:\", test_input_seq[0])\n",
    "print(\"Thông báo dự đoán:\", decoded_sentence)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
